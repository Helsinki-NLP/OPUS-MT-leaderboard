# opus+bt-2020-05-23.zip

* dataset: opus+bt
* model: transformer-align
* source language(s): en
* target language(s): cy
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm4k,spm4k)
* download: [opus+bt-2020-05-23.zip](https://object.pouta.csc.fi/OPUS-MT-models/en-cy/opus+bt-2020-05-23.zip)
* test set translations: [opus+bt-2020-05-23.test.txt](https://object.pouta.csc.fi/OPUS-MT-models/en-cy/opus+bt-2020-05-23.test.txt)
* test set scores: [opus+bt-2020-05-23.eval.txt](https://object.pouta.csc.fi/OPUS-MT-models/en-cy/opus+bt-2020-05-23.eval.txt)

## Training data:  opus+bt

* en-cy: EUbookshop (3045) GNOME (181936) JW300 (27922) KDE4 (38347) QED (18302) Ubuntu (13697) wikibooks.aa (124) wikiquote.aa (1676) wikisource.aa (17752) 
* en-cy: total size = 302801
* total size (opus+bt): 302010


## Validation data

* cy-en: Tatoeba

* devset = top 250  lines of Tatoeba.src.shuffled!
* testset = next 430  lines of Tatoeba.src.shuffled!
* remaining lines are added to traindata

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| Tatoeba.en.cy 	| 32.9 	| 0.559 |
