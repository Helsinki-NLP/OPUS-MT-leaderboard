# opus-2020-07-26.zip

* dataset: opus
* model: transformer
* source language(s): asm awa ben bho gom guj hif_Latn hin jdt_Cyrl kur_Arab kur_Latn mai mar npi ori oss pan_Guru pes pes_Latn pes_Thaa pnb pus rom san_Deva sin snd_Arab tgk_Cyrl tly_Latn urd zza
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-07-26.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/iir-eng/opus-2020-07-26.zip)
* test set translations: [opus-2020-07-26.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/iir-eng/opus-2020-07-26.test.txt)
* test set scores: [opus-2020-07-26.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/iir-eng/opus-2020-07-26.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newsdev2014-hineng.hin.eng 	| 7.9 	| 0.320 |
| newsdev2019-engu-gujeng.guj.eng 	| 7.3 	| 0.296 |
| newstest2014-hien-hineng.hin.eng 	| 11.1 	| 0.367 |
| newstest2019-guen-gujeng.guj.eng 	| 4.9 	| 0.266 |
| Tatoeba-test.asm-eng.asm.eng 	| 12.8 	| 0.314 |
| Tatoeba-test.awa-eng.awa.eng 	| 7.9 	| 0.214 |
| Tatoeba-test.ben-eng.ben.eng 	| 40.7 	| 0.556 |
| Tatoeba-test.bho-eng.bho.eng 	| 24.1 	| 0.439 |
| Tatoeba-test.fas-eng.fas.eng 	| 4.9 	| 0.254 |
| Tatoeba-test.guj-eng.guj.eng 	| 16.0 	| 0.345 |
| Tatoeba-test.hif-eng.hif.eng 	| 1.1 	| 0.205 |
| Tatoeba-test.hin-eng.hin.eng 	| 34.3 	| 0.525 |
| Tatoeba-test.jdt-eng.jdt.eng 	| 11.4 	| 0.101 |
| Tatoeba-test.kok-eng.kok.eng 	| 6.9 	| 0.157 |
| Tatoeba-test.kur-eng.kur.eng 	| 3.5 	| 0.151 |
| Tatoeba-test.lah-eng.lah.eng 	| 20.0 	| 0.301 |
| Tatoeba-test.mai-eng.mai.eng 	| 66.2 	| 0.715 |
| Tatoeba-test.mar-eng.mar.eng 	| 19.7 	| 0.439 |
| Tatoeba-test.multi.eng 	| 19.2 	| 0.405 |
| Tatoeba-test.nep-eng.nep.eng 	| 1.9 	| 0.159 |
| Tatoeba-test.ori-eng.ori.eng 	| 2.3 	| 0.192 |
| Tatoeba-test.oss-eng.oss.eng 	| 1.9 	| 0.179 |
| Tatoeba-test.pan-eng.pan.eng 	| 12.4 	| 0.331 |
| Tatoeba-test.pus-eng.pus.eng 	| 0.9 	| 0.184 |
| Tatoeba-test.rom-eng.rom.eng 	| 1.4 	| 0.173 |
| Tatoeba-test.san-eng.san.eng 	| 2.2 	| 0.165 |
| Tatoeba-test.sin-eng.sin.eng 	| 27.4 	| 0.497 |
| Tatoeba-test.snd-eng.snd.eng 	| 10.2 	| 0.332 |
| Tatoeba-test.tgk-eng.tgk.eng 	| 9.5 	| 0.270 |
| Tatoeba-test.tly-eng.tly.eng 	| 0.8 	| 0.064 |
| Tatoeba-test.urd-eng.urd.eng 	| 22.2 	| 0.419 |
| Tatoeba-test.zza-eng.zza.eng 	| 0.9 	| 0.101 |
