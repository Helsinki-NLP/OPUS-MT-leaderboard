# opusTCv20210807+bt-2021-11-08.zip

* dataset: opusTCv20210807+bt
* model: transformer-big-align
* source language(s): eng
* target language(s): fin
* raw source language(s): eng
* raw target language(s): fin
* model: transformer-big-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opusTCv20210807+bt-2021-11-08.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-fin/opusTCv20210807+bt-2021-11-08.zip)
* test set translations: [opusTCv20210807+bt-2021-11-08.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-fin/opusTCv20210807+bt-2021-11-08.test.txt)
* test set scores: [opusTCv20210807+bt-2021-11-08.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-fin/opusTCv20210807+bt-2021-11-08.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| newsdev2015-enfi.eng-fin 	| 24.6 	| 0.580 	| 1500 	| 23375 	| 1.000 |
| newstest2015-enfi.eng-fin 	| 26.5 	| 0.595 	| 1370 	| 19968 	| 1.000 |
| newstest2016-enfi.eng-fin 	| 28.2 	| 0.607 	| 3000 	| 48116 	| 0.993 |
| newstest2017-enfi.eng-fin 	| 31.4 	| 0.636 	| 3002 	| 45718 	| 0.992 |
| newstest2018-enfi.eng-fin 	| 20.7 	| 0.553 	| 3000 	| 45475 	| 1.000 |
| newstest2019-enfi.eng-fin 	| 26.5 	| 0.581 	| 1997 	| 38369 	| 0.965 |
| newstestB2016-enfi.eng-fin 	| 22.3 	| 0.568 	| 3000 	| 45766 	| 1.000 |
| Tatoeba-test-v2021-08-07.eng-fin 	| 39.9 	| 0.643 	| 10000 	| 60797 	| 0.949 |
