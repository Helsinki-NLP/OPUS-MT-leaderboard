# opusTCv20210807+bt-2021-12-08.zip

* dataset: opusTCv20210807+bt
* model: transformer-big
* source language(s): eng
* target language(s): fin
* raw source language(s): eng
* raw target language(s): fin
* model: transformer-big
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opusTCv20210807+bt-2021-12-08.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-fin/opusTCv20210807+bt-2021-12-08.zip)
* test set translations: [opusTCv20210807+bt-2021-12-08.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-fin/opusTCv20210807+bt-2021-12-08.test.txt)
* test set scores: [opusTCv20210807+bt-2021-12-08.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-fin/opusTCv20210807+bt-2021-12-08.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| newsdev2015-enfi.eng-fin 	| 25.3 	| 0.5846 	| 1500 	| 23375 	| 1.000 |
| newstest2015-enfi.eng-fin 	| 27.9 	| 0.6039 	| 1370 	| 19968 	| 1.000 |
| newstest2016-enfi.eng-fin 	| 29.6 	| 0.6180 	| 3000 	| 48116 	| 0.991 |
| newstest2017-enfi.eng-fin 	| 32.7 	| 0.6486 	| 3002 	| 45718 	| 0.993 |
| newstest2018-enfi.eng-fin 	| 21.5 	| 0.5602 	| 3000 	| 45475 	| 1.000 |
| newstest2019-enfi.eng-fin 	| 26.9 	| 0.5863 	| 1997 	| 38369 	| 0.968 |
| newstestB2016-enfi.eng-fin 	| 23.4 	| 0.5758 	| 3000 	| 45766 	| 1.000 |
| newstestB2017-enfi.eng-fin 	| 27.3 	| 0.6051 	| 3002 	| 45506 	| 0.998 |
| Tatoeba-test-v2021-08-07.eng-fin 	| 38.9 	| 0.6385 	| 10000 	| 60797 	| 0.941 |
