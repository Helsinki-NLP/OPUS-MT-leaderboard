# opus1m+bt-2021-05-01.zip

* dataset: opus1m+bt
* model: transformer-align
* source language(s): lav lit ltg prg sgs
* target language(s): eng
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus1m+bt-2021-05-01.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/bat-eng/opus1m+bt-2021-05-01.zip)
* test set translations: [opus1m+bt-2021-05-01.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/bat-eng/opus1m+bt-2021-05-01.test.txt)
* test set scores: [opus1m+bt-2021-05-01.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/bat-eng/opus1m+bt-2021-05-01.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| newsdev2017-enlv.lav-eng 	| 25.8 	| 0.554 	| 2003 	| 48175 	| 1.000 |
| newsdev2019-enlt.lit-eng 	| 25.1 	| 0.534 	| 2000 	| 49666 	| 0.980 |
| newstest2017-enlv.lav-eng 	| 19.8 	| 0.498 	| 2001 	| 47511 	| 1.000 |
| newstest2019-lten.lit-eng 	| 27.7 	| 0.573 	| 1000 	| 26079 	| 0.956 |
| Tatoeba-test.lav-eng 	| 49.7 	| 0.669 	| 1631 	| 11212 	| 0.979 |
| Tatoeba-test.lit-eng 	| 50.0 	| 0.662 	| 2500 	| 17686 	| 0.971 |
| Tatoeba-test.ltg-eng 	| 18.0 	| 0.328 	| 1 	| 5 	| 1.000 |
| Tatoeba-test.multi-eng 	| 48.2 	| 0.641 	| 4396 	| 30772 	| 0.980 |
| Tatoeba-test.prg-eng 	| 0.7 	| 0.157 	| 213 	| 1663 	| 1.000 |
| Tatoeba-test.sgs-eng 	| 16.9 	| 0.294 	| 52 	| 207 	| 1.000 |
