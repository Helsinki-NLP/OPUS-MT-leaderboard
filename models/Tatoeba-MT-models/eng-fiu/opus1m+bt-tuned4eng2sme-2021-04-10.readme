# opus1m+bt-tuned4eng2sme-2021-04-10.zip

* dataset: opus1m+bt-tuned4eng2sme
* model: transformer-align
* source language(s): eng
* target language(s): sme
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* a sentence initial language token is required in the form of `>>id<<` (id = valid target language ID)
* valid language labels: >>chm<< >>est<< >>fin<< >>fit<< >>fkv<< >>fkv_Latn<< >>hun<< >>izh<< >>kca<< >>koi<< >>kom<< >>kpv<< >>krl<< >>liv<< >>liv_Latn<< >>mdf<< >>mhr<< >>mns<< >>mrj<< >>myv<< >>olo<< >>sia<< >>sjd<< >>sje<< >>sjk<< >>sjt<< >>sju<< >>sma<< >>sme<< >>smj<< >>smn<< >>sms<< >>udm<< >>vep<< >>vot<< >>vro<<
* download: [opus1m+bt-tuned4eng2sme-2021-04-10.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-fiu/opus1m+bt-tuned4eng2sme-2021-04-10.zip)
* test set translations: [opus1m+bt-tuned4eng2sme-2021-04-10.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-fiu/opus1m+bt-tuned4eng2sme-2021-04-10.test.txt)
* test set scores: [opus1m+bt-tuned4eng2sme-2021-04-10.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-fiu/opus1m+bt-tuned4eng2sme-2021-04-10.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| Tatoeba-test.eng-multi 	| 0.4 	| 0.122 	| 10000 	| 59724 	| 1.000 |
| Tatoeba-test.eng-sme 	| 15.2 	| 0.244 	| 62 	| 252 	| 1.000 |
