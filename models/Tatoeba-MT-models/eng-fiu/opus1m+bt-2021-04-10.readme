# opus1m+bt-2021-04-10.zip

* dataset: opus1m+bt
* model: transformer-align
* source language(s): eng
* target language(s): est fin fkv hun izh kom kpv krl liv mdf mhr mrj myv sma sme udm vro
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* a sentence initial language token is required in the form of `>>id<<` (id = valid target language ID)
* valid language labels: >>chm<< >>est<< >>fin<< >>fit<< >>fkv<< >>fkv_Latn<< >>hun<< >>izh<< >>kca<< >>koi<< >>kom<< >>kpv<< >>krl<< >>liv<< >>liv_Latn<< >>mdf<< >>mhr<< >>mns<< >>mrj<< >>myv<< >>olo<< >>sia<< >>sjd<< >>sje<< >>sjk<< >>sjt<< >>sju<< >>sma<< >>sme<< >>smj<< >>smn<< >>sms<< >>udm<< >>vep<< >>vot<< >>vro<<
* download: [opus1m+bt-2021-04-10.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-fiu/opus1m+bt-2021-04-10.zip)
* test set translations: [opus1m+bt-2021-04-10.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-fiu/opus1m+bt-2021-04-10.test.txt)
* test set scores: [opus1m+bt-2021-04-10.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-fiu/opus1m+bt-2021-04-10.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| newsdev2015-enfi.eng-fin 	| 15.1 	| 0.486 	| 1500 	| 23375 	| 0.995 |
| newsdev2018-enet.eng-est 	| 16.6 	| 0.487 	| 2000 	| 34508 	| 0.988 |
| newssyscomb2009.eng-hun 	| 12.7 	| 0.443 	| 502 	| 9733 	| 0.990 |
| newstest2009.eng-hun 	| 13.3 	| 0.438 	| 2525 	| 54965 	| 0.983 |
| newstest2015-enfi.eng-fin 	| 16.5 	| 0.496 	| 1370 	| 19968 	| 0.995 |
| newstest2016-enfi.eng-fin 	| 17.5 	| 0.507 	| 3000 	| 48116 	| 0.962 |
| newstest2017-enfi.eng-fin 	| 20.0 	| 0.528 	| 3002 	| 45718 	| 0.973 |
| newstest2018-enet.eng-est 	| 17.2 	| 0.496 	| 2000 	| 36236 	| 0.978 |
| newstest2018-enfi.eng-fin 	| 13.5 	| 0.468 	| 3000 	| 45475 	| 1.000 |
| newstest2019-enfi.eng-fin 	| 16.7 	| 0.483 	| 1997 	| 38369 	| 0.929 |
| newstestB2016-enfi.eng-fin 	| 14.4 	| 0.480 	| 3000 	| 45766 	| 1.000 |
| newstestB2017-enfi.eng-fin 	| 16.4 	| 0.494 	| 3002 	| 45506 	| 0.977 |
| Tatoeba-test.eng-chm 	| 0.9 	| 0.167 	| 71 	| 376 	| 0.905 |
| Tatoeba-test.eng-est 	| 45.3 	| 0.654 	| 1359 	| 7986 	| 0.967 |
| Tatoeba-test.eng-fin 	| 30.5 	| 0.560 	| 10000 	| 60488 	| 0.924 |
| Tatoeba-test.eng-fkv 	| 1.2 	| 0.029 	| 71 	| 560 	| 0.945 |
| Tatoeba-test.eng-hun 	| 30.9 	| 0.551 	| 10000 	| 58812 	| 0.959 |
| Tatoeba-test.eng-izh 	| 2.2 	| 0.025 	| 6 	| 22 	| 1.000 |
| Tatoeba-test.eng-kom 	| 1.2 	| 0.040 	| 15 	| 42 	| 1.000 |
| Tatoeba-test.eng-krl 	| 1.9 	| 0.076 	| 149 	| 698 	| 1.000 |
| Tatoeba-test.eng-liv 	| 0.5 	| 0.031 	| 33 	| 165 	| 1.000 |
| Tatoeba-test.eng-mdf 	| 3.4 	| 0.096 	| 7 	| 29 	| 1.000 |
| Tatoeba-test.eng-multi 	| 31.1 	| 0.551 	| 10000 	| 59724 	| 0.947 |
| Tatoeba-test.eng-myv 	| 1.4 	| 0.098 	| 25 	| 105 	| 0.767 |
| Tatoeba-test.eng-sma 	| 0.8 	| 0.049 	| 47 	| 188 	| 1.000 |
| Tatoeba-test.eng-sme 	| 12.4 	| 0.238 	| 62 	| 252 	| 1.000 |
| Tatoeba-test.eng-udm 	| 3.4 	| 0.125 	| 10 	| 39 	| 1.000 |
| Tatoeba-test.eng-vro 	| 2.1 	| 0.030 	| 5 	| 40 	| 0.922 |
