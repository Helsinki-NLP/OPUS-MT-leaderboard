# opusTCv20210807+bt_transformer-big_2022-03-13.zip

* dataset: opusTCv20210807+bt
* model: transformer-big
* source language(s): eng
* target language(s): spa
* raw source language(s): eng
* raw target language(s): spa
* model: transformer-big
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opusTCv20210807+bt_transformer-big_2022-03-13.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-spa/opusTCv20210807+bt_transformer-big_2022-03-13.zip)
* test set translations: [opusTCv20210807+bt_transformer-big_2022-03-13.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-spa/opusTCv20210807+bt_transformer-big_2022-03-13.test.txt)
* test set scores: [opusTCv20210807+bt_transformer-big_2022-03-13.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-spa/opusTCv20210807+bt_transformer-big_2022-03-13.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| newssyscomb2009.eng-spa 	| 31.3 	| 0.58391 	| 502 	| 12506 	| 0.998 |
| news-test2008.eng-spa 	| 30.1 	| 0.56595 	| 2051 	| 52596 	| 0.999 |
| newstest2009.eng-spa 	| 30.3 	| 0.57884 	| 2525 	| 68114 	| 1.000 |
| newstest2010.eng-spa 	| 37.5 	| 0.62334 	| 2489 	| 65522 	| 1.000 |
| newstest2011.eng-spa 	| 39.0 	| 0.62460 	| 3003 	| 79476 	| 0.980 |
| newstest2012.eng-spa 	| 39.5 	| 0.62941 	| 3003 	| 79006 	| 0.966 |
| newstest2013.eng-spa 	| 35.9 	| 0.60383 	| 3000 	| 70528 	| 0.959 |
| Tatoeba-test-v2021-08-07.eng-spa 	| 56.9 	| 0.73626 	| 10000 	| 80493 	| 0.990 |
| tico19-test.eng-spa 	| 52.9 	| 0.73528 	| 2100 	| 66591 	| 0.941 |
