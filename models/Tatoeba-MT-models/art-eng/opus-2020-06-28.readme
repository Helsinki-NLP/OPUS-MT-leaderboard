# opus-2020-06-28.zip

* dataset: opus
* model: transformer
* source language(s): afh_Latn avk_Latn bzt_Latn dws_Latn epo ido ido_Latn ile_Latn ina_Latn jbo jbo_Cyrl jbo_Latn ldn_Latn lfn_Cyrl lfn_Latn nov_Latn qya qya_Latn sjn_Latn tlh_Latn tzl tzl_Latn vol_Latn
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-06-28.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/art-eng/opus-2020-06-28.zip)
* test set translations: [opus-2020-06-28.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/art-eng/opus-2020-06-28.test.txt)
* test set scores: [opus-2020-06-28.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/art-eng/opus-2020-06-28.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| Tatoeba-test.afh-eng.afh.eng 	| 1.1 	| 0.097 |
| Tatoeba-test.avk-eng.avk.eng 	| 0.6 	| 0.108 |
| Tatoeba-test.bzt-eng.bzt.eng 	| 0.8 	| 0.109 |
| Tatoeba-test.dws-eng.dws.eng 	| 0.7 	| 0.039 |
| Tatoeba-test.epo-eng.epo.eng 	| 34.7 	| 0.529 |
| Tatoeba-test.ido-eng.ido.eng 	| 13.8 	| 0.318 |
| Tatoeba-test.ile-eng.ile.eng 	| 5.7 	| 0.234 |
| Tatoeba-test.ina-eng.ina.eng 	| 5.7 	| 0.251 |
| Tatoeba-test.jbo-eng.jbo.eng 	| 0.2 	| 0.113 |
| Tatoeba-test.ldn-eng.ldn.eng 	| 0.3 	| 0.082 |
| Tatoeba-test.lfn-eng.lfn.eng 	| 1.5 	| 0.169 |
| Tatoeba-test.multi.eng 	| 11.9 	| 0.291 |
| Tatoeba-test.nov-eng.nov.eng 	| 3.9 	| 0.209 |
| Tatoeba-test.qya-eng.qya.eng 	| 0.3 	| 0.076 |
| Tatoeba-test.sjn-eng.sjn.eng 	| 1.0 	| 0.081 |
| Tatoeba-test.tlh-eng.tlh.eng 	| 0.2 	| 0.124 |
| Tatoeba-test.tzl-eng.tzl.eng 	| 1.1 	| 0.125 |
| Tatoeba-test.vol-eng.vol.eng 	| 0.6 	| 0.115 |
