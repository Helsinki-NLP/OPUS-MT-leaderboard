# opus2m-2020-08-12.zip

* dataset: opus2m
* model: transformer
* source language(s): afh_Latn avk_Latn dws_Latn epo ido ido_Latn ile_Latn ina_Latn jbo jbo_Cyrl jbo_Latn ldn_Latn lfn_Cyrl lfn_Latn nov_Latn qya qya_Latn sjn_Latn tlh_Latn tzl tzl_Latn vol_Latn
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus2m-2020-08-12.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/art-eng/opus2m-2020-08-12.zip)
* test set translations: [opus2m-2020-08-12.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/art-eng/opus2m-2020-08-12.test.txt)
* test set scores: [opus2m-2020-08-12.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/art-eng/opus2m-2020-08-12.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| Tatoeba-test.afh-eng.afh.eng 	| 1.2 	| 0.099 |
| Tatoeba-test.avk-eng.avk.eng 	| 0.4 	| 0.105 |
| Tatoeba-test.dws-eng.dws.eng 	| 1.6 	| 0.076 |
| Tatoeba-test.epo-eng.epo.eng 	| 34.6 	| 0.530 |
| Tatoeba-test.ido-eng.ido.eng 	| 12.7 	| 0.310 |
| Tatoeba-test.ile-eng.ile.eng 	| 4.6 	| 0.218 |
| Tatoeba-test.ina-eng.ina.eng 	| 5.8 	| 0.254 |
| Tatoeba-test.jbo-eng.jbo.eng 	| 0.2 	| 0.115 |
| Tatoeba-test.ldn-eng.ldn.eng 	| 0.7 	| 0.083 |
| Tatoeba-test.lfn-eng.lfn.eng 	| 1.8 	| 0.172 |
| Tatoeba-test.multi.eng 	| 11.6 	| 0.287 |
| Tatoeba-test.nov-eng.nov.eng 	| 5.1 	| 0.215 |
| Tatoeba-test.qya-eng.qya.eng 	| 0.7 	| 0.113 |
| Tatoeba-test.sjn-eng.sjn.eng 	| 0.9 	| 0.090 |
| Tatoeba-test.tlh-eng.tlh.eng 	| 0.2 	| 0.124 |
| Tatoeba-test.tzl-eng.tzl.eng 	| 1.4 	| 0.109 |
| Tatoeba-test.vol-eng.vol.eng 	| 0.5 	| 0.115 |
