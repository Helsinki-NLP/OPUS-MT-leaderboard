# opusTCv20210807_transformer-big_2022-09-15.zip

* dataset: opusTCv20210807
* model: transformer-big
* source language(s): bel bel_Latn bos_Cyrl bos_Latn bul ces csb csb_Latn dsb hbs hbs_Cyrl hrv hsb mkd orv_Cyrl pol rue rus slv srp_Cyrl srp_Latn ukr
* target language(s): ast cat fra gcf_Latn glg ita lad lad_Latn lat_Latn mol oci osp_Latn pms pob por ron scn spa
* raw source language(s): bel bos bul ces csb dsb hbs hrv hsb mkd orv pol rue rus slv srp ukr
* raw target language(s): ast cat fra gcf glg ita lad lat mol oci osp pms pob por ron scn spa
* model: transformer-big
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* a sentence initial language token is required in the form of `>>id<<` (id = valid target language ID)
* valid language labels: 
* download: [opusTCv20210807_transformer-big_2022-09-15.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/sla-itc/opusTCv20210807_transformer-big_2022-09-15.zip)
* test set translations: [opusTCv20210807_transformer-big_2022-09-15.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/sla-itc/opusTCv20210807_transformer-big_2022-09-15.test.txt)
* test set scores: [opusTCv20210807_transformer-big_2022-09-15.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/sla-itc/opusTCv20210807_transformer-big_2022-09-15.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| Tatoeba-test-v2021-08-07.multi-multi 	| 47.4 	| 0.65914 	| 10000 	| 67265 	| 0.963 |
